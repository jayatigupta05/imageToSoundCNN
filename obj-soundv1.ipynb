{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eabfd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from ultralytics import YOLO\n",
    "except:\n",
    "    %pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f27b8",
   "metadata": {},
   "source": [
    "## 0. Imports and agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7dda84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4ed5c",
   "metadata": {},
   "source": [
    "## 1. Object detection using YOLO11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97308bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\jayat\\projects\\object identification with cnn\\pics\\dog.png: 640x480 1 dog, 196.6ms\n",
      "Speed: 11.5ms preprocess, 196.6ms inference, 14.7ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model using the 'coco8.yaml' dataset for 3 epochs\n",
    "# results = model.train(data=\"coco.yaml\", epochs=3)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "# results = model.val()\n",
    "\n",
    "# Perform object detection on an image using the model\n",
    "# results = model(\"https://ultralytics.com/images/bus.jpg\")\n",
    "\n",
    "# Export the model to ONNX format\n",
    "# success = model.export(format=\"onnx\")\n",
    "\n",
    "img_path = Path(\"pics\\dog.png\")\n",
    "results = model(img_path)\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449b339",
   "metadata": {},
   "source": [
    "## 2. Integrating OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trackers\n",
    "seen_objects = {}    # {label: first_seen_time}\n",
    "stable_objects = set()    # objects seen after 30 seconds\n",
    "\n",
    "# Live feed capture from port 0 (in-built webcam)\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO detection\n",
    "    results = model(frame)\n",
    "    boxes = results[0].boxes\n",
    "    detected_labels = []\n",
    "\n",
    "    # Extract detected class names\n",
    "    if boxes is not None:\n",
    "        for c in boxes.cls:\n",
    "            label = model.names[int(c)]\n",
    "            detected_labels.append(label)\n",
    "\n",
    "    # Track objects\n",
    "    current_time = time.time()\n",
    "    for label in detected_labels:\n",
    "        if label not in seen_objects:\n",
    "            seen_objects[label] = current_time  # first seen\n",
    "        else:\n",
    "            if (current_time - seen_objects[label] > 30) and (label not in stable_objects):\n",
    "                stable_objects.add(label)\n",
    "                # speak(label)\n",
    "    \n",
    "    # Reset if object disappears\n",
    "    for label in list(seen_objects.keys()):\n",
    "        if label not in detected_labels:\n",
    "            seen_objects.pop(label)\n",
    "            stable_objects.discard(label)\n",
    "\n",
    "    # Show annotated frame\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv.imshow(\"YOLO Live Feed\", annotated_frame)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b30482d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[ 33,  53,  58],\n",
       "         [ 31,  50,  54],\n",
       "         [ 32,  50,  53],\n",
       "         ...,\n",
       "         [ 23,  43,  55],\n",
       "         [ 25,  44,  55],\n",
       "         [ 27,  45,  56]],\n",
       " \n",
       "        [[ 31,  52,  57],\n",
       "         [ 30,  50,  54],\n",
       "         [ 32,  50,  54],\n",
       "         ...,\n",
       "         [ 23,  43,  55],\n",
       "         [ 25,  44,  55],\n",
       "         [ 27,  45,  55]],\n",
       " \n",
       "        [[ 29,  53,  56],\n",
       "         [ 28,  50,  55],\n",
       "         [ 31,  51,  56],\n",
       "         ...,\n",
       "         [ 22,  43,  55],\n",
       "         [ 23,  43,  54],\n",
       "         [ 25,  44,  54]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[110, 137, 147],\n",
       "         [120, 149, 157],\n",
       "         [115, 149, 153],\n",
       "         ...,\n",
       "         [ 84,  92, 139],\n",
       "         [ 96, 106, 150],\n",
       "         [120, 130, 173]],\n",
       " \n",
       "        [[118, 143, 153],\n",
       "         [121, 147, 156],\n",
       "         [120, 151, 157],\n",
       "         ...,\n",
       "         [ 83,  87, 136],\n",
       "         [ 89,  93, 141],\n",
       "         [118, 123, 169]],\n",
       " \n",
       "        [[120, 143, 154],\n",
       "         [117, 142, 151],\n",
       "         [122, 151, 158],\n",
       "         ...,\n",
       "         [ 76,  78, 129],\n",
       "         [ 72,  75, 124],\n",
       "         [102, 105, 153]]], shape=(480, 640, 3), dtype=uint8)\n",
       " orig_shape: (480, 640)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\jayat\\\\projects\\\\object identification with cnn\\\\runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 1.8329001031816006, 'inference': 91.24270011670887, 'postprocess': 0.9924001060426235}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc883da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([0., 0., 0., 0.])\n",
       "conf: tensor([0.5470, 0.4729, 0.4045, 0.2511])\n",
       "data: tensor([[2.2241e+02, 2.8653e+02, 6.3871e+02, 4.7960e+02, 5.4696e-01, 0.0000e+00],\n",
       "        [4.2605e+02, 1.3574e+02, 6.3951e+02, 4.7938e+02, 4.7292e-01, 0.0000e+00],\n",
       "        [2.2357e+02, 1.3052e+02, 6.3413e+02, 4.7870e+02, 4.0452e-01, 0.0000e+00],\n",
       "        [8.0767e+00, 3.1055e+02, 4.6079e+02, 4.7948e+02, 2.5106e-01, 0.0000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (480, 640)\n",
       "shape: torch.Size([4, 6])\n",
       "xywh: tensor([[430.5599, 383.0649, 416.2933, 193.0662],\n",
       "        [532.7832, 307.5628, 213.4586, 343.6426],\n",
       "        [428.8454, 304.6066, 410.5607, 348.1816],\n",
       "        [234.4332, 395.0142, 452.7130, 168.9332]])\n",
       "xywhn: tensor([[0.6727, 0.7981, 0.6505, 0.4022],\n",
       "        [0.8325, 0.6408, 0.3335, 0.7159],\n",
       "        [0.6701, 0.6346, 0.6415, 0.7254],\n",
       "        [0.3663, 0.8229, 0.7074, 0.3519]])\n",
       "xyxy: tensor([[222.4132, 286.5318, 638.7065, 479.5980],\n",
       "        [426.0539, 135.7415, 639.5125, 479.3842],\n",
       "        [223.5650, 130.5158, 634.1257, 478.6974],\n",
       "        [  8.0767, 310.5476, 460.7897, 479.4808]])\n",
       "xyxyn: tensor([[0.3475, 0.5969, 0.9980, 0.9992],\n",
       "        [0.6657, 0.2828, 0.9992, 0.9987],\n",
       "        [0.3493, 0.2719, 0.9908, 0.9973],\n",
       "        [0.0126, 0.6470, 0.7200, 0.9989]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932328ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
