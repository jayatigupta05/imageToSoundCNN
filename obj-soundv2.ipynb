{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabfd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from ultralytics import YOLO\n",
    "except:\n",
    "    %pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f27b8",
   "metadata": {},
   "source": [
    "## 0. Imports and agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7dda84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4ed5c",
   "metadata": {},
   "source": [
    "## 1. Object detection using YOLO11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97308bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\jayat\\projects\\object identification with cnn\\pics\\bus.jpg: 640x480 4 persons, 1 bus, 216.0ms\n",
      "Speed: 4.4ms preprocess, 216.0ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model using the 'coco8.yaml' dataset for 3 epochs\n",
    "# results = model.train(data=\"coco.yaml\", epochs=3)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "# results = model.val()\n",
    "\n",
    "# Export the model to ONNX format\n",
    "# success = model.export(format=\"onnx\")\n",
    "\n",
    "img_path = Path(\"pics/bus.jpg\")\n",
    "results = model(img_path)\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998cf842",
   "metadata": {},
   "source": [
    "## 2. Function to check stable objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f321c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global trackers\n",
    "seen_objects = {}      # {label: first_seen_time}\n",
    "stable_objects = set() # objects confirmed for 30s\n",
    "\n",
    "def update_object_tracking(detected_labels, seen_objects, stable_objects, threshold=30):\n",
    "    \"\"\"\n",
    "    Update seen_objects and stable_objects based on detected_labels.\n",
    "    \n",
    "    Args:\n",
    "        detected_labels (list): list of class labels detected in current frame\n",
    "        seen_objects (dict): {label: first_seen_time}\n",
    "        stable_objects (set): set of labels confirmed after threshold seconds\n",
    "        threshold (int): time in seconds before confirming object as stable\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (seen_objects, stable_objects)\n",
    "    \"\"\"\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Track newly seen or persistent objects\n",
    "    for label in detected_labels:\n",
    "        if label not in seen_objects:\n",
    "            seen_objects[label] = current_time\n",
    "        else:\n",
    "            if (current_time - seen_objects[label] > threshold) and (label not in stable_objects):\n",
    "                stable_objects.add(label)\n",
    "\n",
    "    # Reset objects that disappeared\n",
    "    for label in list(seen_objects.keys()):\n",
    "        if label not in detected_labels:\n",
    "            seen_objects.pop(label, None)\n",
    "            stable_objects.discard(label)\n",
    "\n",
    "    return seen_objects, stable_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b61ea9",
   "metadata": {},
   "source": [
    "## 3. TTS function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41939e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "def speak_objects(objects):\n",
    "    \"\"\"\n",
    "    Convert a set of object labels into speech.\n",
    "    Args:\n",
    "        objects (set): set of labels (strings)\n",
    "    \"\"\"\n",
    "    if not objects:\n",
    "        return\n",
    "    engine = pyttsx3.init()\n",
    "    for obj in objects:\n",
    "        engine.say(f\"I see a {obj}\")\n",
    "    engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449b339",
   "metadata": {},
   "source": [
    "## 4. Final loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_object_detection():\n",
    "    model = YOLO(\"yolo11n.pt\")  # Load YOLO model\n",
    "\n",
    "    seen_objects = {}\n",
    "    stable_objects = set()\n",
    "\n",
    "    cap = cv.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        # Run YOLO detection\n",
    "        results = model(frame)\n",
    "        boxes = results[0].boxes\n",
    "        detected_labels = []\n",
    "\n",
    "        if boxes is not None:\n",
    "            for c in boxes.cls:\n",
    "                label = model.names[int(c)]\n",
    "                detected_labels.append(label)\n",
    "\n",
    "        # Update trackers\n",
    "        seen_objects, stable_objects, new_stable = update_object_tracking(\n",
    "            detected_labels, seen_objects, stable_objects, threshold=30\n",
    "        )\n",
    "\n",
    "        # Speak newly stable objects\n",
    "        if new_stable:\n",
    "            speak_objects(new_stable)\n",
    "\n",
    "        # Show annotated frame\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv.imshow(\"YOLO Live Feed\", annotated_frame)\n",
    "\n",
    "        # Quit if 'q' is pressed\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    print(\"Stable objects (seen for 30s):\", stable_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdff8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_object_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b30482d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[ 33,  53,  58],\n",
       "         [ 31,  50,  54],\n",
       "         [ 32,  50,  53],\n",
       "         ...,\n",
       "         [ 23,  43,  55],\n",
       "         [ 25,  44,  55],\n",
       "         [ 27,  45,  56]],\n",
       " \n",
       "        [[ 31,  52,  57],\n",
       "         [ 30,  50,  54],\n",
       "         [ 32,  50,  54],\n",
       "         ...,\n",
       "         [ 23,  43,  55],\n",
       "         [ 25,  44,  55],\n",
       "         [ 27,  45,  55]],\n",
       " \n",
       "        [[ 29,  53,  56],\n",
       "         [ 28,  50,  55],\n",
       "         [ 31,  51,  56],\n",
       "         ...,\n",
       "         [ 22,  43,  55],\n",
       "         [ 23,  43,  54],\n",
       "         [ 25,  44,  54]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[110, 137, 147],\n",
       "         [120, 149, 157],\n",
       "         [115, 149, 153],\n",
       "         ...,\n",
       "         [ 84,  92, 139],\n",
       "         [ 96, 106, 150],\n",
       "         [120, 130, 173]],\n",
       " \n",
       "        [[118, 143, 153],\n",
       "         [121, 147, 156],\n",
       "         [120, 151, 157],\n",
       "         ...,\n",
       "         [ 83,  87, 136],\n",
       "         [ 89,  93, 141],\n",
       "         [118, 123, 169]],\n",
       " \n",
       "        [[120, 143, 154],\n",
       "         [117, 142, 151],\n",
       "         [122, 151, 158],\n",
       "         ...,\n",
       "         [ 76,  78, 129],\n",
       "         [ 72,  75, 124],\n",
       "         [102, 105, 153]]], shape=(480, 640, 3), dtype=uint8)\n",
       " orig_shape: (480, 640)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\jayat\\\\projects\\\\object identification with cnn\\\\runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 1.8329001031816006, 'inference': 91.24270011670887, 'postprocess': 0.9924001060426235}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc883da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "932328ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'person'},\n",
       " {'person': 1757265861.5026045,\n",
       "  'cell phone': 1757265912.8324695,\n",
       "  'remote': 1757265913.7522285})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_objects, seen_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf97690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
